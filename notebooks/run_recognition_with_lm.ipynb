{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDPATH = Path(\"/sbtal/riksdag-video/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARPA_PATH = Path(\"/home/joregan/lm_arpa/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_MAPPING = {}\n",
    "with open(\"/home/joregan/rdapi_subset\") as ss:\n",
    "    for line in ss.readlines():\n",
    "        parts = line.split()\n",
    "        FILE_MAPPING[parts[0]] = parts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode import build_ctcdecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SWE_MODEL = \"KBLab/wav2vec2-large-voxrex-swedish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joregan/miniconda3/envs/hf/lib/python3.10/site-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Downloading: 100%|██████████| 1.96k/1.96k [00:00<00:00, 776kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(model=_SWE_MODEL, device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(_SWE_MODEL)\n",
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(lmid):\n",
    "    return build_ctcdecoder(\n",
    "        labels=list(sorted_vocab_dict.keys()),\n",
    "        kenlm_model_path=str(ARPA_PATH / f\"{lmid}.3gram.arpa\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio(audio_id):\n",
    "    parameters=[\"-ac\", \"1\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\"]\n",
    "    video_path = VIDPATH / f\"{audio_id}_480p.mp4\"\n",
    "    video = AudioSegment.from_file(str(video_path), \"mp4\")\n",
    "    outname = f\"/tmp/{audio_id}.wav\"\n",
    "    video.export(outname, format=\"wav\", parameters=parameters)\n",
    "    return outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH = Path(\"/home/joregan/subset_w2vlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(JSON_PATH / f\"{audid}.json\"), \"w\") as jsonf:\n",
    "    json.dump(output, jsonf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mapping in FILE_MAPPING.items():\n",
    "    lmid, audio = mapping\n",
    "    OUTFILE = JSON_PATH / f\"{audio}.json\"\n",
    "    if not OUTFILE.exists():\n",
    "        print(mapping)\n",
    "        wavfile = convert_audio(audio)\n",
    "        decoder = build_decoder(lmid)\n",
    "        output = pipe(wavfile, chunk_length_s=10, return_timestamps=\"word\", decoder=decoder)\n",
    "        with open(str(OUTFILE), \"w\") as jsonf:\n",
    "            json.dump(output, jsonf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = set([y for x, y in FILE_MAPPING.items()])\n",
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse = {}\n",
    "with open(\"mappings.tsv\", \"w\") as mappings:\n",
    "    for api, audio in FILE_MAPPING.items():\n",
    "        if audio in reverse:\n",
    "            continue\n",
    "        reverse[audio] = api\n",
    "        mappings.write(f\"{api}\\t{audio}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "323572f3d7d63e949a9798ea1062be3bd23d8f1ad1664ecc50859e690c42d8f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
