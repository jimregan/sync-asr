{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDPATH = Path(\"/sbtal/riksdag-video/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARPA_PATH = Path(\"/home/joregan/lm_arpa/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_MAPPING = {}\n",
    "with open(\"/home/joregan/rdapi_subset\") as ss:\n",
    "    for line in ss.readlines():\n",
    "        parts = line.split()\n",
    "        FILE_MAPPING[parts[0]] = parts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode import build_ctcdecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SWE_MODEL = \"KBLab/wav2vec2-large-voxrex-swedish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joregan/miniconda3/envs/hf/lib/python3.10/site-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Downloading: 100%|██████████| 1.96k/1.96k [00:00<00:00, 776kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(model=_SWE_MODEL, device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(_SWE_MODEL)\n",
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(lmid):\n",
    "    return build_ctcdecoder(\n",
    "        labels=list(sorted_vocab_dict.keys()),\n",
    "        kenlm_model_path=str(ARPA_PATH / f\"{lmid}.3gram.arpa\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio(audio_id):\n",
    "    parameters=[\"-ac\", \"1\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\"]\n",
    "    video_path = VIDPATH / f\"{audio_id}_480p.mp4\"\n",
    "    video = AudioSegment.from_file(str(video_path), \"mp4\")\n",
    "    outname = f\"/tmp/{audio_id}.wav\"\n",
    "    video.export(outname, format=\"wav\", parameters=parameters)\n",
    "    return outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /home/joregan/lm_arpa/H001AU12.3gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "Only 684 unigrams passed as vocabulary. Is this small or artificial data?\n"
     ]
    }
   ],
   "source": [
    "lmid = \"H001AU12\"\n",
    "audid = \"2442207150019764521\"\n",
    "decoder = build_decoder(lmid)\n",
    "wavfile = convert_audio(audid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(wavfile, chunk_length_s=10, return_timestamps=\"word\", decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH = Path(\"/home/joregan/subset_w2vlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(JSON_PATH / f\"{audid}.json\"), \"w\") as jsonf:\n",
    "    json.dump(output, jsonf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mapping in FILE_MAPPING.items():\n",
    "    lmid, audio = mapping\n",
    "    OUTFILE = JSON_PATH / f\"{audio}.json\"\n",
    "    if not OUTFILE.exists():\n",
    "        print(mapping)\n",
    "        wavfile = convert_audio(audio)\n",
    "        decoder = build_decoder(lmid)\n",
    "        output = pipe(wavfile, chunk_length_s=10, return_timestamps=\"word\", decoder=decoder)\n",
    "        with open(str(OUTFILE), \"w\") as jsonf:\n",
    "            json.dump(output, jsonf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FILE_MAPPING)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "323572f3d7d63e949a9798ea1062be3bd23d8f1ad1664ecc50859e690c42d8f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
